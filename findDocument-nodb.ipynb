{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getText(filePath):\n",
    "    '''Get text from pdf file'''\n",
    "    doc = fitz.open(filePath)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text+=page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    '''Remove stop word'''\n",
    "    stop_words = set(stopwords.words('english')) # Define the set of English stopwords\n",
    "    words = nltk.word_tokenize(text) # Tokenize the input text\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words] # Remove stopwords\n",
    "    return ' '.join(filtered_words) # Join the filtered words into a string\n",
    "\n",
    "def stem_words(text):\n",
    "    '''convert to root word'''\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return ' '.join(stems)\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "def clean_text(filePath):\n",
    "    text = getText(filePath)\n",
    "    text = text.lower()\n",
    "    text = remove_urls(text) # remove url\n",
    "    # text = ''.join([i for i in text if not i.isdigit()]) #remove number\n",
    "    text = re.sub(r'\\d+', '', text) #remove number\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove special character\n",
    "    text = remove_stopwords(text) # remove stop word\n",
    "    text = stem_words(text) #conver words to root words\n",
    "    text = re.sub(r'_{2,}', '', text)\n",
    "    text = text.encode('ascii', 'ignore').decode() #remove character not ascii\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_files = 'D:\\\\Document-CSDLDPT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1  CLASS ACTION SETTLEMENT AGREEMENT AND RELEASE 5.pdf',\n",
       " '1 Approved April 9 2010 Revised April 12 2019 AST Guidelines for.pdf',\n",
       " '900 History geography and auxiliary disciplines.pdf',\n",
       " 'A Literature Review on Trade and Informal Labour Markets in Developing Countries.pdf',\n",
       " 'A-level Philosophy Specification Specification for first teaching.PDF',\n",
       " 'An overview of scientific and scholarly journal publishing.pdf',\n",
       " 'AP World History Modern Course and Exam Description Effective.pdf',\n",
       " 'ASEAN Model Contractual Clauses for Cross Border Data Flows.pdf',\n",
       " 'Asphalt Art Safety Study.pdf',\n",
       " 'ATTACK Design and Philosophy subs revision.pdf',\n",
       " 'Brick by Brick Wikipedia and Libraries building on each other.pdf',\n",
       " 'California Data Breach Report.pdf',\n",
       " 'California Pay Data Reporting Portal.pdf',\n",
       " 'CalPERS Health Program Guide.pdf',\n",
       " 'Code and Data for the Social Sciences.pdf',\n",
       " 'Community ART Group Toolkit.pdf',\n",
       " 'convension de palermo.pdf',\n",
       " 'Cost of a Data Breach Report 2022.pdf',\n",
       " 'Data Protection by Design and by Default.pdf',\n",
       " 'Data Quality Framework for EU medicines regulation.pdf',\n",
       " 'Data Strategy of the Secretary.pdf',\n",
       " 'DDC Dewey Decimal Classification  SUMMARIES.pdf',\n",
       " 'DV-2024-Instructions.pdf',\n",
       " 'English Literature Specification for first teaching.PDF',\n",
       " 'English Literature.pdf',\n",
       " 'Ethnicity and Interests at the 1990 Federated States of Micronesia.pdf',\n",
       " 'EUROPEAN SOLIDARITY CORPS.pdf',\n",
       " 'Evaluating Information Online.pdf',\n",
       " 'Evaluation of Corporate Compliance Programs.pdf',\n",
       " 'First Meeting of Regional Network of Legal And Technical Experts.pdf',\n",
       " 'Foul Tales Public Knowledge Bringing Dantes Divine Comedy to.pdf',\n",
       " 'From Cradle to Cane The C st of Being a Female C nsumer.pdf',\n",
       " 'Garfield E The Agony and the Ecstasy  The History and Meaning of.pdf',\n",
       " 'GCSE (9-1) History.pdf',\n",
       " 'GCSE 91 History  Specification.pdf',\n",
       " 'GPT4 System Card  OpenAI.pdf',\n",
       " 'GradientBased Learning Applied to Document Recognition.pdf',\n",
       " 'Guidelines for performing Systematic Literature Reviews.pdf',\n",
       " 'Harnessing the Power of Data in Health.pdf',\n",
       " 'History, geography, and auxiliary disciplines.pdf',\n",
       " 'HISTORYSYLLABUS.pdf',\n",
       " 'History_Curriculum.pdf',\n",
       " 'How to Write a Paper in Scientific Journal Style and Format.pdf',\n",
       " 'How-to-Write-Guide-v10-2014.pdf',\n",
       " 'Images of Evil Images of Kings_ The Contrasting Faces of the Roy.pdf',\n",
       " 'Intermediality Intertextuality and Remediation A Literary.pdf',\n",
       " 'Investing to shape our future.pdf',\n",
       " 'ISTANBUL DOCUMENT 1999.pdf',\n",
       " 'iterature Review on practices and methods on the assessment.pdf',\n",
       " 'IWHYM CHOW FLAME OF LOVE.pdf',\n",
       " 'Joint Committee Final Report on Big Data.pdf',\n",
       " 'Kentucky_Academic_Standards_Arts_and_Humanities.pdf',\n",
       " 'KEVIN M MILLER MD  Los Angeles.pdf',\n",
       " 'Kevin-Miller-CV.pdf',\n",
       " 'Library of Congress Classification Outline Class B  Philosophy.pdf',\n",
       " 'Library of Congress Classification Outline.pdf',\n",
       " 'Literary Lab.pdf',\n",
       " 'Literature Survey, Data, and Stylized Facts.pdf',\n",
       " 'Macroprudential policy - a literature review.pdf',\n",
       " 'Making Love Legible in China Politics and Society during the.pdf',\n",
       " 'MALE AND FEMALE HE CREATED THEM.pdf',\n",
       " 'Meditations On First Philosophy.pdf',\n",
       " 'Messages from the academic literature on risk measurement for the trading book.pdf',\n",
       " 'Monitoring of medical literature and the entry of relevant.pdf',\n",
       " 'Multimedia_Database_Management_Systems_(Artech House).pdf',\n",
       " 'nature-positive-plan.pdf',\n",
       " 'Negotiated Agreement text initialled by the EU and OACPS chief.pdf',\n",
       " 'Nurse Corps Scholarship Program.pdf',\n",
       " 'On Traumatic Knowledge and Literary Studies.pdf',\n",
       " 'PHILOSOPHY PROGRAMME.pdf',\n",
       " 'Philosophy Syllabus.pdf',\n",
       " 'Philosophy, parapsychology and occultism,.pdf',\n",
       " 'PhilosophyPastPapers.pdf',\n",
       " 'Platform Recommendations on Data and Usability.pdf',\n",
       " 'Precision Centigrade Temperature Sensors datasheet.pdf',\n",
       " 'Programme of Action.pdf',\n",
       " 'programme-of-work-to-develop-a-consensus-solution-to-the-tax-challenges-arising-from-the-digitalisation-of-the-economy.pdf',\n",
       " 'Queer Love  David M Halperin.pdf',\n",
       " 'Registered Exporter System REX Guidance document.pdf',\n",
       " 'Report on the Thematic Review on effective risk data aggregation and risk reporting.pdf',\n",
       " 'Stanford University Dataset.pdf',\n",
       " 'Syllabus Cambridge IGCSE History 0470.pdf',\n",
       " 'System of EnvironmentalEconomic Accounting 2012Central.pdf',\n",
       " 'Text as Data The Promise and Pitfalls of Automatic Content Analysis.pdf',\n",
       " 'The Art Market 2018.pdf',\n",
       " 'The arts.pdf',\n",
       " 'The Basic Business Philosophy of the Panasonic Group.pdf',\n",
       " 'The Emergence of a New Asset Class.pdf',\n",
       " 'The Gender Earnings Gap in the Gig Economy Evidence from over.pdf',\n",
       " 'The History and Meaning of the Journal Impact Factor.pdf',\n",
       " 'The Ontario Curriculum Grades 18 The Arts 2009 revised.pdf',\n",
       " 'THE ONTARIO CURRICULUM.pdf',\n",
       " 'The Stockholm Programme.pdf',\n",
       " 'trio-programmer.pdf',\n",
       " 'UNAIDS DATA 2018.pdf',\n",
       " 'Vienna Convention on the Law of Treaties 1969.pdf',\n",
       " 'Visual Arts, Music, Dance, and Theatre.pdf',\n",
       " 'Visual Arts.pdf',\n",
       " 'What Is Changing Lives Through Literature.pdf',\n",
       " 'Work Programme 2023-2024.pdf',\n",
       " 'World History Modern.pdf']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "listFile = os.listdir(path_to_files)\n",
    "listFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listText = []\n",
    "for file in listFile:\n",
    "    # path = os.path.join('documents', file)\n",
    "    # print(path)\n",
    "    text = clean_text(os.path.join(path_to_files, file))\n",
    "    listText.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer(min_df=2)\n",
    "X = tfidfvec.fit_transform(listText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer()\n",
    "X2 = countVec.fit_transform(listText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listFile.pickle', 'wb') as file:\n",
    "    pickle.dump(listFile, file)\n",
    "\n",
    "with open('listText.pickle', 'wb') as file:\n",
    "    pickle.dump(listText, file)\n",
    "\n",
    "with open('tfidfvec.pickle', 'wb') as file:\n",
    "    pickle.dump(tfidfvec, file)\n",
    "\n",
    "with open('countVec.pickle', 'wb') as file:\n",
    "    pickle.dump(countVec, file)\n",
    "\n",
    "with open('tfidf-file-to-vec.pickle', 'wb') as file:\n",
    "    pickle.dump(X, file)\n",
    "    \n",
    "with open('count-file-to-vec.pickle', 'wb') as file:\n",
    "    pickle.dump(X2, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('pythonenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da81743f5e5325665d1b6157bdd4f0c695488c1af8b8fba7eb689df38b91f087"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
